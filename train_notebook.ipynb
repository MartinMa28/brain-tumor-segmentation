{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from models.fcn import VGGNet, FCN8sScaledBN, FCN8sScaled\n",
    "from models.unet import UNet\n",
    "from datasets.BRATS2018 import BRATS2018, NormalizeBRATS, ToTensor, ZeroPad\n",
    "from metrics.metrics import Evaluator\n",
    "from metrics.torch_seg_metrics import *\n",
    "from torchvision import transforms\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import logging\n",
    "from logging.config import fileConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_dataloader(input_data_type, seg_type, batch_size):\n",
    "    data_transforms = transforms.Compose([\n",
    "            ZeroPad(),\n",
    "            NormalizeBRATS(),\n",
    "            ToTensor()\n",
    "        ])\n",
    "    \n",
    "    if input_data_type == 't1ce':\n",
    "        data_set = {\n",
    "            phase: BRATS2018('./BRATS2018/',\\\n",
    "                            data_set=phase,\\\n",
    "                            seg_type=seg_type,\\\n",
    "                            transform=data_transforms)\n",
    "            for phase in ['train', 'val']\n",
    "        }\n",
    "    elif input_data_type == 'flair':\n",
    "        data_set = {\n",
    "            phase: BRATS2018('./BRATS2018/',\\\n",
    "                            data_set=phase,\\\n",
    "                            scan_type='flair',\\\n",
    "                            seg_type=seg_type,\\\n",
    "                            transform=data_transforms)\n",
    "            for phase in ['train', 'val']\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError('Scan type must be t1ce or flair!')\n",
    "    \n",
    "\n",
    "    data_loader = {\n",
    "        'train': DataLoader(data_set['train'], batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "        'val': DataLoader(data_set['val'], batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    }\n",
    "\n",
    "    return data_set, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fcn_model(num_classes, use_gpu):\n",
    "    vgg_model = VGGNet(pretrained=False, requires_grad=True, remove_fc=True, batch_norm=True)\n",
    "    fcn_model = FCN8sScaledBN(pretrained_net=vgg_model, n_class=num_classes)\n",
    "\n",
    "    if use_gpu:\n",
    "        ts = time.time()\n",
    "        # vgg_model = vgg_model.to(device)\n",
    "        fcn_model = fcn_model.to(device)\n",
    "        \n",
    "        print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))\n",
    "    \n",
    "    return fcn_model\n",
    "\n",
    "\n",
    "def get_unet_model(input_channels, num_classes, use_gpu):\n",
    "    # vgg_model = VGGEncoder(pretrained=True, requires_grad=True, remove_fc=True)\n",
    "    # unet = UNetWithVGGEncoder(vgg_model, num_classes)\n",
    "    unet = UNet(input_channels, num_classes)\n",
    "    if use_gpu:\n",
    "        ts = time.time()\n",
    "        unet = unet.to(device)\n",
    "\n",
    "        print(\"Finish cuda loading, time elapsed {}\".format(time.time() - ts))\n",
    "    \n",
    "    return unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stamp() -> str:\n",
    "    ts = time.time()\n",
    "    time_stamp = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "    \n",
    "    def dice_coef(self, preds, targets):\n",
    "        smooth = 5e-3\n",
    "        num = preds.size(0)              # batch size\n",
    "        preds_flat = preds.view(num, -1).float()\n",
    "        targets_flat = targets.view(num, -1).float()\n",
    "\n",
    "        intersection = (preds_flat * targets_flat).sum()\n",
    "        logger.debug('intersection: {:.4f}, sum_preds: {:.4f}, sum_targets: {:.4f}'.format(intersection,\\\n",
    "            preds_flat.sum(),\\\n",
    "            targets_flat.sum()))\n",
    "\n",
    "        return (2. * intersection + smooth) / (preds_flat.sum() + targets_flat.sum() + smooth)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        score = self.dice_coef(probs[:, 1, :, :], targets)\n",
    "        score = 1 - score\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_data_type, seg_type, num_classes, batch_size, epochs, use_gpu, learning_rate, w_decay, score_dir, logger):\n",
    "    logger.info(f'Start training using {input_data_type} modal.')\n",
    "    # model = get_unet_model(1, num_classes, use_gpu)\n",
    "    model = get_fcn_model(num_classes, use_gpu)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.25, 0.75]).to(device))\n",
    "    # criterion = SoftDiceLoss()\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=w_decay)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)  # decay LR by a factor of 0.5 every 5 epochs\n",
    "    \n",
    "    data_set, data_loader = get_dataset_dataloader(input_data_type, seg_type, batch_size)\n",
    "\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_dice = 0.0\n",
    "    epoch_loss = np.zeros((2, epochs))\n",
    "    epoch_acc = np.zeros((2, epochs))\n",
    "    epoch_class_acc = np.zeros((2, epochs))\n",
    "    epoch_mean_iou = np.zeros((2, epochs))\n",
    "    epoch_mean_dice = np.zeros((2, epochs))\n",
    "    evaluator = Evaluator(num_classes)\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            logger.info('Epoch {}/{}'.format(epoch + 1, epochs))\n",
    "            logger.info('-' * 28)\n",
    "\n",
    "\n",
    "            for phase_ind, phase in enumerate(['train', 'val']):\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                    logger.info(phase)\n",
    "                else:\n",
    "                    model.eval()\n",
    "                    logger.info(phase)\n",
    "\n",
    "                evaluator.reset()\n",
    "                running_loss = 0.0\n",
    "                running_dice = 0.0\n",
    "\n",
    "                for batch_ind, batch in enumerate(data_loader[phase]):\n",
    "                    imgs, targets = batch\n",
    "                    imgs = imgs.to(device)\n",
    "                    targets = targets.to(device)\n",
    "\n",
    "                    # zero the learnable parameters gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(imgs)\n",
    "                        loss = criterion(outputs, targets)\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    preds = torch.argmax(F.softmax(outputs, dim=1), dim=1)\n",
    "                    running_loss += loss * imgs.size(0)\n",
    "                    dice = (dice_score(preds, targets, logger) * imgs.size(0))\n",
    "                    running_dice = np.nansum([dice, running_dice], axis=0)\n",
    "                    logger.debug('Batch {} running loss: {:.4f}, dice score: {:.4f}'.format(batch_ind,\\\n",
    "                        running_loss,\\\n",
    "                        running_dice))\n",
    "\n",
    "                    # test the iou and pixelwise accuracy using evaluator\n",
    "                    preds = preds.cpu().numpy()\n",
    "                    targets = targets.cpu().numpy()\n",
    "                    evaluator.add_batch(targets, preds)\n",
    "\n",
    "\n",
    "                epoch_loss[phase_ind, epoch] = running_loss / len(data_set[phase])\n",
    "                epoch_mean_dice[phase_ind, epoch] = running_dice / len(data_set[phase])\n",
    "                epoch_acc[phase_ind, epoch] = evaluator.Pixel_Accuracy()\n",
    "                epoch_class_acc[phase_ind, epoch] = evaluator.Pixel_Accuracy_Class()\n",
    "                epoch_mean_iou[phase_ind, epoch] = evaluator.Mean_Intersection_over_Union()\n",
    "\n",
    "                logger.info('{} loss: {:.4f}, acc: {:.4f}, class acc: {:.4f}, mean iou: {:.6f}, mean dice score: {:.6f}'.format(phase,\\\n",
    "                    epoch_loss[phase_ind, epoch],\\\n",
    "                    epoch_acc[phase_ind, epoch],\\\n",
    "                    epoch_class_acc[phase_ind, epoch],\\\n",
    "                    epoch_mean_iou[phase_ind, epoch],\\\n",
    "                    epoch_mean_dice[phase_ind, epoch]))\n",
    "\n",
    "\n",
    "                if phase == 'val' and epoch_mean_dice[phase_ind, epoch] > best_dice:\n",
    "                    best_dice = epoch_mean_dice[phase_ind, epoch]\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "                if phase == 'val' and (epoch + 1) % 10 == 0:\n",
    "                    logger.info(f'Saved model.state_dict in epoch {epoch + 1}')\n",
    "                    torch.save(model.state_dict(), os.path.join(score_dir, f'epoch{epoch + 1}_model.pt'))\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        logger.info('Training completed in {}m {}s'.format(int(time_elapsed / 60),\\\n",
    "            int(time_elapsed) % 60))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "\n",
    "        # save numpy results\n",
    "        np.save(os.path.join(score_dir, 'epoch_accuracy'), epoch_acc)\n",
    "        np.save(os.path.join(score_dir, 'epoch_mean_iou'), epoch_mean_iou)\n",
    "        np.save(os.path.join(score_dir, 'epoch_mean_dice'), epoch_mean_dice)\n",
    "\n",
    "        return model, optimizer\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        np.save(os.path.join(score_dir, 'interrupted_epoch_accuracy'), epoch_acc)\n",
    "        np.save(os.path.join(score_dir, 'interrupted_epoch_mean_iou'), epoch_mean_iou)\n",
    "        np.save(os.path.join(score_dir, 'interrupted_epoch_mean_dice'), epoch_mean_dice)\n",
    "\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        \n",
    "        return model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "if not os.path.exists('logs/'):\n",
    "    os.makedirs('logs/')\n",
    "    os.mknod('logs/basic_logs.log')\n",
    "    \n",
    "fileConfig('./logging_conf.ini')\n",
    "logger = logging.getLogger('main')\n",
    "\n",
    "n_classes = 2\n",
    "batch_size = 4\n",
    "epochs = 50\n",
    "lr = 1e-2\n",
    "#momentum = 0\n",
    "w_decay = 1e-5\n",
    "step_size = 5\n",
    "gamma = 0.5\n",
    "configs = \"UNets-BRATS2018-TC-CrossEntropy_batch{}_training_epochs{}_Adam_scheduler-step{}-gamma{}_lr{}_w_decay{}\".format(batch_size, epochs, step_size, gamma, lr, w_decay)\n",
    "\n",
    "input_data_type = 't1ce'\n",
    "\n",
    "score_dir = os.path.join(\"scores\", configs)\n",
    "if not os.path.exists(score_dir):\n",
    "    os.makedirs(score_dir)\n",
    "    \n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if use_gpu else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-23 16:26:47,069 - main - INFO - Start training using t1ce modal.\n",
      "2019-04-23 16:26:49,238 - main - INFO - Epoch 1/50\n",
      "2019-04-23 16:26:49,239 - main - INFO - ----------------------------\n",
      "2019-04-23 16:26:49,240 - main - INFO - train\n",
      "2019-04-23 16:26:54,608 - main - DEBUG - -Dice score- intersection: 332.00, preds: 72898.00, targets: 689.00\n",
      "2019-04-23 16:26:54,609 - main - DEBUG - Batch 0 running loss: 2.6874, dice score: 0.0361\n",
      "2019-04-23 16:27:00,151 - main - DEBUG - -Dice score- intersection: 0.00, preds: 2175.00, targets: 1228.00\n",
      "2019-04-23 16:27:00,152 - main - DEBUG - Batch 1 running loss: 5.0387, dice score: 0.0361\n",
      "2019-04-23 16:27:05,789 - main - INFO - Saved model.state_dict\n"
     ]
    }
   ],
   "source": [
    "model, optimizer = train(input_data_type, seg_type='tc', num_classes=n_classes, batch_size=batch_size,\\\n",
    "                         epochs=epochs, use_gpu=use_gpu, learning_rate=lr, w_decay=w_decay,\\\n",
    "                         score_dir=score_dir, logger=logger)\n",
    "\n",
    "logger.info('Saved model.state_dict')\n",
    "torch.save(model.state_dict(), os.path.join(score_dir, f'{time_stamp()}_trained_model.pt'))\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, os.path.join(score_dir, f'{time_stamp()}_trained_model_checkpoint.tar'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
